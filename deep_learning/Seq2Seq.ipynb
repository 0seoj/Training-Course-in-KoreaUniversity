{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5zthtOlIjcO1","colab_type":"text"},"source":["**Copyright(C). Cheonbok Park. All rights reserved.**\n","\n","Email : cb_park@korea.ac.kr"]},{"cell_type":"markdown","metadata":{"id":"lWPhKRrqw8Vl","colab_type":"text"},"source":["### 필요 라이브러리 설치"]},{"cell_type":"code","metadata":{"id":"krquphUSw64W","colab_type":"code","colab":{}},"source":["# 필요한 라이브러리를 설치합니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF6swkROGoRk","colab_type":"code","colab":{}},"source":["import torch # torch library \n","import torch.nn as nn # Nueral Network에 대한 package\n","import numpy as np  # numpy \n","import editdistance # 평가 지표로서 사용될 edit distance \n","import matplotlib.pyplot as plt # plot 을 찍기 위한 라이브러리\n","import tqdm\n","import torch.nn.functional as F # pytorch function 들을 사용하기 위한 용도 \n","from torch.utils import data # dataset 관련된 utility 를 사용하려는 용도\n","from random import choice, randrange # random\n","from itertools import zip_longest \n","import librosa\n","import os   # directory 생성 및 디렉토리 생성과 관련된 package \n","import json \n","import random\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvgO0Z-3xKpr","colab_type":"text"},"source":["### Data Loader "]},{"cell_type":"markdown","metadata":{"id":"N5VY4V8ifgNm","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/word-encoding.png)"]},{"cell_type":"code","metadata":{"id":"JPt35iPSs0dO","colab_type":"code","colab":{}},"source":["def batch(iterable, n=1):\n","    args = [iter(iterable)] * n\n","    return zip_longest(*args)\n","\n","\n","def pad_tensor(vec, pad, value=0, dim=0):\n","    \"\"\"\n","    pad token으로 채우는 용도 \n","    args:\n","        vec - tensor to pad\n","        pad - the size to pad to\n","        dim - dimension to pad\n","    return:\n","        a new tensor padded to 'pad' in dimension 'dim'\n","    \"\"\"\n","    pad_size = pad - vec.shape[0]\n","\n","    if len(vec.shape) == 2:\n","        zeros = torch.ones((pad_size, vec.shape[-1])) * value\n","    elif len(vec.shape) == 1:\n","        zeros = torch.ones((pad_size,)) * value\n","    else:\n","        raise NotImplementedError\n","    return torch.cat([torch.Tensor(vec), zeros], dim=dim)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t-W0gQps2rg","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/Kuhh0.jpg)"]},{"cell_type":"code","metadata":{"id":"QAaKIfA7BdLX","colab_type":"code","colab":{}},"source":["def pad_collate(batch, values=(0, 0), dim=0):\n","    \"\"\"\n","    데이터 로더에 들어가기전에 batch화 할 때 거치는 함수 \n","    args:\n","        batch - list of (tensor, label)\n","    reutrn:\n","        xs - a tensor of all examples in 'batch' after padding\n","        ys - a LongTensor of all labels in batch\n","        ws - a tensor of sequence lengths\n","    \"\"\"\n","\n","    sequence_lengths = torch.Tensor([int(x[0].shape[dim]) for x in batch]) # 각 batch 마다 길이를 얻어내고 \n","    sequence_lengths, xids = sequence_lengths.sort(descending=True) # 감소하는 순서로 정렬\n","    target_lengths = torch.Tensor([int(x[1].shape[dim]) for x in batch])\n","    # find longest sequence (가장 긴 sequence의 길이를 구함 )\n","    src_max_len = max(map(lambda x: x[0].shape[dim], batch))\n","    tgt_max_len = max(map(lambda x: x[1].shape[dim], batch))\n","    # pad according to max_len (max length 만큼 padd를 추가 )\n","    batch = [(pad_tensor(x, pad=src_max_len, dim=dim), pad_tensor(y, pad=tgt_max_len, dim=dim)) for (x, y) in batch]\n","\n","    # stack all\n","    xs = torch.stack([x[0] for x in batch], dim=0)\n","    ys = torch.stack([x[1] for x in batch], dim=0)\n","    xs = xs[xids].contiguous() # decreasing order로 다시 나열 \n","    ys = ys[???].contiguous() # xids 와 같은 순서로 \n","    target_lengths = target_lengths[???] \n","    return xs.long(), ys.????(), sequence_lengths.int(), target_lengths.int()\n","\n","\n","class ToyDataset(data.Dataset):\n","    \"\"\"\n","    https://talbaumel.github.io/blog/attention/\n","    \"\"\"\n","    def __init__(self, min_length=5, max_length=20, type='train'):\n","        self.SOS = \"<s>\"  # all strings will end with the End Of String token )\n","        self.EOS = \"</s>\"  # all strings will end with the End Of String token\n","        self.characters = list(\"abcdefg\")\n","        self.int2char = list(self.characters)\n","        self.char2int = {c: i+3 for i, c in enumerate(self.characters)} # +3 을 왜하는 가?\n","        print(self.char2int)\n","        self.VOCAB_SIZE = len(self.characters)\n","        self.min_length = min_length\n","        self.max_length = max_length\n","        \n","        # train set or test set 을 생성 \n","        if type == 'train':\n","            self.set = [self._sample() for _ in range(4000)]\n","        else:\n","            self.set = [self._sample() for _ in range(300)]\n","\n","    def __len__(self):\n","        # 필수 ! \n","        return len(self.set)\n","\n","    def __getitem__(self, item):\n","        # 필수 !\n","        return self.set[item]\n","\n","    def _sample(self):\n","        random_length = randrange(self.min_length, self.max_length)  # Pick a random length\n","        random_char_list = [choice(self.characters[:-1]) for _ in range(random_length)]  # Pick random chars\n","        random_string = ''.join(random_char_list)\n","        a = np.array([self.char2int.get(x) for x in random_string]+[2])\n","        b = np.array([self.char2int.get(x) for x in random_string[::-1]] + [2]) # Return the random string and its reverse + EOS \n","        \n","        return a, b\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QcWCIsJzltc","colab_type":"text"},"source":["### utils misc.py\n","\n"]},{"cell_type":"code","metadata":{"id":"SciyvlCzBe-B","colab_type":"code","colab":{}},"source":["EOS_TOKEN = '</s>'\n","\n","\n","def check_size(tensor, *args):\n","    size = [a for a in args]\n","    assert tensor.size() == torch.Size(size), tensor.size()\n","\n","def to_mono(y):\n","    assert y.ndim == 2\n","    return np.mean(y, axis=1)\n","\n","\n","def edit_distance(guess, truth):\n","    guess = guess.split(EOS_TOKEN)[0]\n","    truth = truth[3:].split(EOS_TOKEN)[0]\n","    return editdistance.eval(guess, truth) / len(truth)\n","\n","\n","class AttrDict(dict):\n","  __getattr__ = dict.__getitem__\n","  __setattr__ = dict.__setitem__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a0Hv4JFBzM-4","colab_type":"text"},"source":["### Edit distance (편집거리 알고리즘) "]},{"cell_type":"markdown","metadata":{"id":"X4ct9e_OzuTT","colab_type":"text"},"source":["![대체 텍스트](https://raw.githubusercontent.com/sumitc91/data/master/askgif-blog/9e07d056-ccf7-4fc8-b6ee-000c8032b9ec_editDistance.gif)"]},{"cell_type":"code","metadata":{"id":"cwbk7k7h4PKB","colab_type":"code","colab":{}},"source":["# edit distance 란 편집 거리 \n","\n","\n","ref = [1, 2, 3, 4]\n","hyp = [1, 2, 4, 5, 6]\n","editdistance.eval(ref,hyp)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1VtDggGzzs_","colab_type":"text"},"source":["### Attention Mask"]},{"cell_type":"code","metadata":{"id":"BOMNQN6Gj_-p","colab_type":"code","colab":{}},"source":["## 추후에 설명 Decoder section\n","def mask_3d(inputs, seq_len, mask_value=0.):\n","    batches = inputs.size()[0]\n","    assert batches == len(seq_len) # length 체크 \n","    max_idx = max(seq_len) # max length 체크 \n","    for n, idx in enumerate(seq_len): # length 에서 의미없는 hidden state attention 값은 0으로 두기 위한 mask값 설정 \n","        if idx < max_idx.item():\n","            if len(inputs.size()) == 3:\n","                inputs[n, idx.int():, :] = mask_value\n","            else:\n","                assert len(inputs.size()) == 2, \"The size of inputs must be 2 or 3, received {}\".format(inputs.size())\n","                inputs[n, idx.int():] = mask_value\n","    return inputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXtIVGUgHmws","colab_type":"text"},"source":["## Encoder RNN"]},{"cell_type":"markdown","metadata":{"id":"LdFDvktffm9k","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/encoder-network.png)"]},{"cell_type":"markdown","metadata":{"id":"Qf62OoGcwJP5","colab_type":"text"},"source":["#### Embedding Module "]},{"cell_type":"markdown","metadata":{"id":"c8mNg3ve8LmT","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/S0NJzq7/embedding.png)"]},{"cell_type":"markdown","metadata":{"id":"kH2OnZrXwOqk","colab_type":"text"},"source":["#### GRU Module"]},{"cell_type":"markdown","metadata":{"id":"goSiSeiq8bn-","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/881BygH/GRU.png)"]},{"cell_type":"markdown","metadata":{"id":"L_TIF6h58dZf","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/NsMqvcH/GRU-param.png)"]},{"cell_type":"markdown","metadata":{"id":"g-Z_vgd2wSAd","colab_type":"text"},"source":["#### ENCODER RNN Code"]},{"cell_type":"code","metadata":{"id":"8d__61m2HfFR","colab_type":"code","colab":{}},"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","class EncoderRNN(nn.Module):\n","    def __init__(self, config):\n","        super(EncoderRNN, self).__init__()\n","        self.input_size = config[\"n_channels\"]\n","        self.hidden_size = config[\"encoder_hidden\"]\n","        self.layers = config.get(\"encoder_layers\", 1)\n","        \n","        self.dropout = config.get(\"encoder_dropout\", 0.) \n","        self.bi = config.get(\"bidirectional_encoder\", False)\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.???(config.get(\"n_classes\", 32), ????, padding_idx=??)\n","        gru_input_dim = ????\n","        self.rnn = nn.????(\n","            gru_input_dim,\n","            self.hidden_size,\n","            self.layers,\n","            dropout=self.dropout,\n","            bidirectional=self.bi,\n","            batch_first=True)# model 선언 \n","        self.gpu = config.get(\"gpu\", False) \n","\n","\n","\n","    def forward(self, inputs, hidden, input_lengths):\n","        \n","        # pack padded 를 통하여 input을 감싸기 \n","        inputs = self.????(inputs)\n","        \n","        x = pack_padded_sequence(inputs, input_lengths, batch_first=True) # ??? 무엇일까?\n","        output, state = self.rnn(x, hidden)\n","        output, _ = pad_packed_sequence(output, batch_first=True, padding_value=0.) # sequence 를 위의 그림과 같이 pack함 \n","        \n","        if self.bi: # bidirectional 의 경우 forward와 backward를 sum하여 사용한다. or concat \n","            output = output[:, :, :self.????] ??? output[:, :, self.????:]\n","            state = state[:1] +state[1:]\n","        return output, state\n","\n","    def init_hidden(self, batch_size):\n","        # hidden state가 없는 초기 상태일때 \n","        h0 = torch.???(2 if self.bi else 1, batch_size, self.hidden_size)\n","        if self.gpu:\n","            h0 = h0.cuda()\n","        return h0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZSYZqWVwM_z","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"]},{"cell_type":"markdown","metadata":{"id":"l8yDzSXKHnyB","colab_type":"text"},"source":["### Decoder "]},{"cell_type":"code","metadata":{"id":"X83Lj_GBHojW","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super(Decoder, self).__init__()\n","        self.batch_size = config[\"batch_size\"]\n","        self.hidden_size = config[\"decoder_hidden\"]\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.Embedding(config.get(\"n_classes\", 32), self.embedding_dim, ???=0)\n","        self.rnn = nn.???(\n","            input_size=self.embedding_dim+self.hidden_size if config['decoder'].lower() == 'bahdanau' else self.embedding_dim,\n","            hidden_size=self.hidden_size,\n","            num_layers=config.get(\"decoder_layers\", 1),\n","            dropout=config.get(\"decoder_dropout\", 0),\n","            bidirectional=????,\n","            batch_first=True)\n","        if config['decoder'] != \"RNN\":\n","            self.attention = Attention(\n","                self.batch_size,\n","                self.hidden_size,\n","                method=config.get(\"attention_score\", \"dot\"))\n","\n","        self.gpu = config.get(\"gpu\", False)\n","        self.decoder_output_fn = F.log_softmax if config.get('loss', 'NLL') == 'NLL' else None\n","\n","    def forward(self, **kwargs):\n","        \"\"\" Must be overrided \"\"\"\n","        raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcUzMxqV9Lr2","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/gvpn1RT/bmm.png)"]},{"cell_type":"markdown","metadata":{"id":"CBkw-82hE3MU","colab_type":"text"},"source":["![대체 텍스트](http://cnyah.com/2017/08/01/attention-variants/attention-mechanisms.png)"]},{"cell_type":"code","metadata":{"id":"IYbzCRP6HuLD","colab_type":"code","colab":{}},"source":["class BahdanauDecoder(Decoder):\n","    \"\"\"\n","        Corresponds to BahdanauAttnDecoderRNN in Pytorch tutorial\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(BahdanauDecoder, self).__init__(config)\n","        self.output_size = config.get(\"n_classes\", 32)\n","        self.character_distribution = nn.Linear(self.hidden_size, self.???)\n","\n","    def forward(self, **kwargs):\n","        \"\"\"\n","        :param input: [B]\n","        :param prev_context: [B, H]\n","        :param prev_hidden: [B, H]\n","        :param encoder_outputs: [B, T, H]\n","        :return: output (B), context (B, H), prev_hidden (B, H), weights (B, T)\n","        \"\"\"\n"," \n","        input = kwargs[\"input\"] # decoder input \n","        prev_hidden = kwargs[\"prev_hidden\"] # decoder rnn 에서 들어갈 previous hidden state \n","        encoder_outputs = kwargs[\"encoder_outputs\"] # encoder RNN에서 Encoding이 끝난 (B,L,hidden_size)  \n","        seq_len = kwargs.get(\"seq_len\", None) # sequence length \n","\n","        # check inputs\n","        \n","       \n","\n","        # Attention weights\n","        weights = self.attention.forward(prev_hidden, encoder_outputs, seq_len)  # B x T\n","        context = weights.unsqueeze(1).???(encoder_outputs).squeeze(1)  #[B,1,T] [B,T,H] -> [B x H]\n","\n","        # embed characters\n","        embedded = self.embedding(input).unsqueeze(0)\n","        \n","        #attention 을 통해 얻어낸 context를 추가하여 모델에 input으로 제공\n","        rnn_input = torch.???((embedded, ???.unsqueeze(0)), 2)\n","\n","        outputs, hidden = self.rnn(rnn_input.transpose(1, 0), prev_hidden.unsqueeze(0)) # 1 x B x N, B x N\n","\n","        \n","        output = self.????(outputs.squeeze(0)) # logit 값 각 chracter 별로\n","\n","        if self.decoder_output_fn:\n","            # NLL loss 인 경우 \n","            output = self.decoder_output_fn(output, -1)\n","\n","        if len(output.size()) == 3:\n","            output = output.squeeze(1)\n","\n","        return output, hidden.squeeze(0), weights\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHhtZXhUEQ64","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/tiQkz.png)"]},{"cell_type":"code","metadata":{"id":"kYfGqtu0eqZy","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    \"\"\"\n","    Inputs:\n","        last_hidden: (batch_size, hidden_size)\n","        encoder_outputs: (batch_size, max_time, hidden_size)\n","    Returns:\n","        attention_weights: (batch_size, max_time)\n","    \"\"\"\n","    def __init__(self, batch_size, hidden_size, method=\"dot\"):\n","        super(Attention, self).__init__()\n","        self.method = method\n","        self.hidden_size = hidden_size\n","        if method == 'dot':\n","            pass\n","        elif method == 'general':\n","            # Wa (hidden,hidden)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","        elif method == \"concat\":\n","            # Wa : (2*hidden,hidden)\n","            # Va : (hidden,1)\n","            self.Wa = nn.Linear(2*hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        elif method == 'bahdanau':\n","            # Wa : (hidden_size,hidden_size) \n","            # Ua : (hidden_size,hidden_size)\n","            # Va : (hidden_size,1)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.Ua = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        else:\n","            raise NotImplementedError\n","\n","        \n","    def forward(self, last_hidden, encoder_outputs, seq_len=None):\n","        \"\"\"\n","        Inputs :\n","          last_hidden : (B,T,hidden_size)\n","          encoder_outputs : \n","          seq_len:  \n","        Returns:\n","          attention matrix : \n","        \"\"\"\n","        batch_size, seq_lens, _ = encoder_outputs.size()\n","        # attention energies 를 구하기 \n","        attention_energies = self._score(last_hidden, encoder_outputs, self.method)\n","        \n","        if seq_len is not None:\n","            attention_energies = mask_3d(attention_energies, seq_len, -float('inf'))\n","\n","        return F.softmax(attention_energies, -1)\n","\n","    def _score(self, last_hidden, encoder_outputs, method):\n","        \"\"\"\n","        Computes an attention score\n","        :param last_hidden: (batch_size, hidden_dim)\n","        :param encoder_outputs: (batch_size, max_time, hidden_dim)\n","        :param method: str (`dot`, `general`, `concat`)\n","        :return:\n","        \"\"\"\n","\n","        # assert last_hidden.size() == torch.Size([batch_size, self.hidden_size]), last_hidden.size()\n","        \n","        if method == 'dot':\n","            last_hidden = last_hidden.unsqueeze(-1) # (batch_size, hidden_dim,1)\n","            \n","            # attention : (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            \n","            return ???.bmm(last_hidden).squeeze(-1)  \n","\n","        elif method == 'general':\n","            # dot 이랑 비슷 다만 last hidden을 한번 projection\n","            x = self.??(last_hidden) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim)\n","            x = x.unsqueeze(-1) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim,1)\n","            # encoded 된 hidden states 와 dot proudct를 수행하기 \n","            # attention: (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            return ???.bmm(x).squeeze(-1)\n","\n","        elif method == \"concat\":\n","            x = last_hidden.unsqueeze(1).expand_as(encoder_outputs) # (batch_size, hidden_dim) ->  (batch_size,1, hidden_dim)\n","            # concat 후 -> linear 거치기 -> 후 tanh\n","            x = F.??(self.??(torch.??((x, encoder_outputs), -1))) # (batch_size, max_timestep, hidden_dim) ->  (batch_size,  max_timestep, hidden_dim*2)\n","            # (batch_size, max_timestep, hidden_dim*2) ->  (batch_size,  max_timestep, )\n","            return x.matmul(self.??).squeeze(-1)\n","\n","        elif method == \"bahdanau\":\n","            # mlp 기반의 attention model\n","            \n","            x = last_hidden.unsqueeze(1) # (batch_size, hidden_dim) ->  (batch_size,1, hidden_dim)\n","            # 각각을 projection 후 더하기 -> tanh \n","            out = F.???(self.??(x) ?? self.???(encoder_outputs)) # \n","            return ??.matmul(self.va).squeeze(-1)# (batch_size,max_timestep,hidden_dim) ->  (batch_size, max_timestep)\n","\n","        else:\n","            raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqeFcsDJ7Dz2","colab_type":"text"},"source":["### Seq2Seq Model "]},{"cell_type":"markdown","metadata":{"id":"jS2cmY548vtB","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/CK5wTz5/crossentropy.png)"]},{"cell_type":"markdown","metadata":{"id":"z_rIN2DY80pD","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/ssXZ28q/crossentropy-2.png)"]},{"cell_type":"code","metadata":{"id":"V-axgHRo7C5V","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","        Sequence to sequence module\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(Seq2Seq, self).__init__()\n","        self.SOS = config.get(\"start_index\", 1) # Start index를 가져옵니다. \n","        self.vocab_size = config.get(\"n_classes\", 32) # embedding 에 필요한 vocabulary size \n","        self.batch_size = config.get(\"batch_size\", 1) # batch_size 정보를 가져옵니다.\n","        self.gpu = config.get(\"gpu\", False) # cuda 로 돌아가는지 아닌지에 대한 정보 \n","\n","        # Encoder 선언\n","        \n","        self.encoder = EncoderRNN(config)\n","\n","        # Decoder 선언 \n","        \n","        self.decoder = BahdanauDecoder(config)\n","        \n","        # loss fucntion \n","        # ignore_index =0 왜???\n","        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n","        \n","        \n","\n","    def encode(self, x, x_len):\n","        # encoder를 통해 주어진 source 정보를 Encodeing 하는 용도 \n","        \n","        batch_size = x.size()[0]\n","        # 초기 inital hidden state 만들기\n","        init_state = self.encoder.???_hidden(batch_size)\n","        # encoder Forward 수행 \n","        encoder_outputs, encoder_state = self.???.forward(x, init_state, x_len)\n","        \n","        \n","       \n","        return encoder_outputs, encoder_state.squeeze(0)\n","\n","    def decode(self, encoder_outputs, encoder_hidden, targets, targets_lengths, input_lengths):\n","        \"\"\"\n","        Args:\n","            encoder_outputs: (B, T, H)\n","            encoder_hidden: (B, H)\n","            targets: (B, L)\n","            targets_lengths: (B)\n","            input_lengths: (B)\n","        Vars:\n","            decoder_input: (B)\n","            decoder_context: (B, H)\n","            hidden_state: (B, H)\n","            attention_weights: (B, T)\n","        Outputs:\n","            alignments: (L, T, B)\n","            logits: (B*L, V)\n","            labels: (B*L)\n","        \"\"\"\n","\n","        batch_size = encoder_outputs.size()[0]\n","        max_length = targets.size()[1]\n","        # decoder의 처음 y0 는 무엇이 되어야 할까? *주의해야할 포인트 \n","        if batch_size ==1:\n","          decoder_input = torch.LongTensor([self.???] * batch_size)\n","        else:\n","          decoder_input = torch.LongTensor([self.???] * batch_size).squeeze(-1)\n","        decoder_context = encoder_outputs.transpose(1, 0)[-1] #(Batch,1)\n","        decoder_hidden = encoder_hidden\n","        \n","        #alignments :  attention align을 저장하기 위한 용도  \n","        alignments = torch.zeros(max_length, encoder_outputs.size(1), batch_size) # attention align을 저장하기 위한 용도 \n","        logits = torch.zeros(max_length, batch_size, self.decoder.output_size) # logits 값을 저장하기 위한 용도의 tensor \n","\n","        if self.gpu:\n","            decoder_input = decoder_input.cuda()\n","            decoder_context = decoder_context.cuda()\n","            logits = logits.cuda()\n","        inference = []\n","        for t in range(max_length):\n","\n","            # The decoder accepts, at each time step t :\n","            # - an input, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - encoder outputs, [B, T, H]\n","            \n","            # The decoder outputs, at each time step t :\n","            # - an output, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - weights, [B, T]\n","\n","            outputs, decoder_hidden, attention_weights = self.decoder.forward(\n","                    input=decoder_input.long(),\n","                    prev_hidden=decoder_hidden,\n","                    encoder_outputs=encoder_outputs,\n","                    seq_len=input_lengths)\n","            \n","            alignments[t] = attention_weights.transpose(1, 0)\n","            \n","            \n","            logits[t] = outputs\n","\n","            \n","\n","            if  self.training:\n","                decoder_input = targets[:, t]\n","            else:\n","                topv, topi = outputs.data.topk(1) # 가장 높은 예측만 사용.\n","                decoder_input = topi.squeeze(-1).detach()\n","                inference.append(decoder_input.cpu())\n","\n","        \n","        labels = targets.contiguous().view(-1) \n","\n","        \n","        mask_value = 0\n","        #what is this mask_3d? # (warning check)\n","        logits = mask_3d(logits.transpose(1, 0), targets_lengths, mask_value)\n","        logits = logits.contiguous().view(-1, self.vocab_size) # loss를 구하기 위해 쫙 펴주기 \n","\n","        return logits, labels.long(), alignments,inference\n","\n","    \n","    def step(self, batch):\n","        x, y, x_len, y_len = batch\n","        if self.gpu:\n","            x = x.cuda()\n","            y = y.cuda()\n","            x_len = x_len.cuda()\n","            y_len = y_len.cuda()\n","\n","        encoder_out, encoder_state = self.???(x, x_len) # encoder \n","        logits, labels, alignments,inference = self.???(encoder_out, encoder_state, y, y_len, x_len) # decoder 를 통해 alignment와 logit 값 얻기 \n","        return logits, labels, alignments,inference\n","\n","    def loss(self, batch):\n","        logits, labels, alignments,inference = self.step(batch)\n","        loss = self.loss_fn(????, labels) # loss 구하기 우리는 cross entropy 사용 \n","        return loss, logits, labels, alignments,inference"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbOfjOmU6262","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"markdown","metadata":{"id":"weB4hLTwfV3S","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/seq2seq.png)"]},{"cell_type":"code","metadata":{"id":"NKYVKohKBmpS","colab_type":"code","colab":{}},"source":["def train(model, optimizer, train_loader, epoch,n_epochs):\n","    \n","\n","    losses = []\n","    cers = []\n","\n","    \n","    model.train() # train mode \n","    count = 0\n","    for batch in train_loader:\n","        loss, _, _, _,_ = model.loss(batch)\n","        losses.append(loss.item())\n","        # Reset gradients\n","        optimizer.????()\n","        # Compute gradients\n","        loss.???()\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2)\n","        optimizer.???()\n","  \n","    print ('\\n [{}/{}] avg_loss= {:05.3f}'.format(epoch,n_epochs,np.mean(losses)))\n","    \n","    return model, optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0q5dl-qGtXB","colab_type":"code","colab":{}},"source":["def evaluate(model, eval_loader):\n","\n","    losses = []\n","    accs = []\n","    edits = []\n","    \n","    model.eval() # why?? \n","\n","    with torch.no_grad():\n","        for batch in eval_loader:\n","            #t.set_description(\" Evaluating... (train={})\".format(model.training))\n","            loss, logits, labels, alignments,_ = model.loss(batch)\n","            preds = logits.detach().cpu().numpy()\n","            \n","            acc = 100 *np.sum(np.argmax(preds, -1) == labels.detach().cpu().numpy()) / len(preds)\n","            edit = editdistance.eval(np.argmax(preds, -1), labels.detach().cpu().numpy()) / len(preds)\n","            \n","            losses.append(loss.item())\n","            \n","            accs.append(acc)\n","            edits.append(edit)\n","        \n","        \n","\n","   \n","    print(\"  End of evaluation : loss {:05.3f} , acc {:03.1f} , edits {:03.3f}\".format(np.mean(losses), np.mean(accs), np.mean(edits)))\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWWvvbf68__6","colab_type":"text"},"source":["## 학습을 진행해보도록 하겠습니다"]},{"cell_type":"code","metadata":{"id":"N6zoFKQj8_MU","colab_type":"code","colab":{}},"source":["USE_CUDA = torch.cuda.is_available()\n","batch_size = 32\n","epochs = 6\n","dataset = ToyDataset(5, 15)\n","eval_dataset = ToyDataset(5, 15, type='eval')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKechkHv9EXQ","colab_type":"code","colab":{}},"source":["train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=???, drop_last=True)\n","eval_loader = data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate,drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JapBBgq6KNp2","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"xh2HQkg59sND","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_h_LOmU-AEz","colab_type":"code","colab":{}},"source":["model = Seq2Seq(config)\n","model = model.???()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jXTGn9V-CuD","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.????(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ktMBioF-EAN","colab_type":"code","colab":{}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5RNRT6acajT5","colab_type":"text"},"source":["### 시각화"]},{"cell_type":"code","metadata":{"id":"cQ77ZlPKal2j","colab_type":"code","colab":{}},"source":["import seaborn\n","\n","def draw(data, x, y):\n","    seaborn.heatmap(data, \n","                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n","                    cbar=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3fVzxjganHg","colab_type":"code","colab":{}},"source":["def visualize_plot(model,custom_input= 'cgdafa'):\n","    c_xs = np.array([dataset.char2int.get(x) for x in custom_input]+[2])\n","    c_xs = torch.from_numpy(c_xs).unsqueeze(0).long()\n","\n","    c_xl = torch.tensor(c_xs[0].size()[-1]).unsqueeze(0)\n","\n","    c_ys = np.array([dataset.char2int.get(x) for x in custom_input[::-1]] + [2]) # Return the random string and its reverse + EOS \n","    c_ys = torch.from_numpy(c_ys).unsqueeze(0).long()\n","\n","    c_yl = torch.tensor(c_ys[0].size()[-1]).unsqueeze(0)\n","    c_data = (c_xs,c_ys,c_xl,c_yl)\n","    loss, logits, labels, alignments,predict=model.loss(c_data)\n","    heat_map_value = alignments.detach().cpu().numpy()[:, :, 0]\n","    preds = logits.detach().cpu().numpy()\n","    preds = np.argmax(preds, -1)\n","    source_tokens = [ dataset.int2char[item-3] for item in c_xs[0] if item!=0 if item !=2 ] +['</s>']\n","    target_tokens = [ dataset.int2char[item-3] if item !=2 else '</s>' for item in preds.tolist() if item!=0 ]\n","    draw(heat_map_value,source_tokens,target_tokens)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IkbDmwaY4BG","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZdAsEpjcC0V","colab_type":"text"},"source":["### Dot Mode "]},{"cell_type":"code","metadata":{"id":"T8X3wWrrewkY","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xHTy6m9k7XU","colab_type":"code","colab":{}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LuAGn6wOcMAU","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NNv1KexcOQh","colab_type":"code","colab":{}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"48ACZ__zcgz3","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZio7ZpScXWf","colab_type":"text"},"source":["### Concat Mode "]},{"cell_type":"code","metadata":{"id":"rlEMn4CDcVdv","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvMOke61cbvf","colab_type":"code","colab":{}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCRpTxKVcc__","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjbdwe3jcfFD","colab_type":"code","colab":{}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhnkBB82chid","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMzGeSiUdZRo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}